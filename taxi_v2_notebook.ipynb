{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews.streams import Pipe, Buffer\n",
    "\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "import streamz\n",
    "import streamz.dataframe\n",
    "\n",
    "import random, sys, gym, math, bokeh, pdb, time\n",
    "\n",
    "from simple_agent import SimpleAgent\n",
    "from drop_pick_agent import DropPickAgent\n",
    "from decomp_agent import DecompAgent\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_episode(env, agent):\n",
    "    state = env.reset()\n",
    "    episode_return = 0\n",
    "    episode = []\n",
    "    while True:\n",
    "        action = agent.select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        \n",
    "        episode_return += reward\n",
    "        episode.append((state, action, reward))\n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            return episode, episode_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate episodes into batches\n",
    "batch_size = 1\n",
    "\n",
    "# Only show this many batches at once\n",
    "max_batches_to_show = 100000\n",
    "\n",
    "# Also apply rolling average to a certain window of batches\n",
    "rolling_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "    df.x = int(df.mean(0))\n",
    "    return df.head(1)\n",
    "\n",
    "training_stream = streamz.Stream()\n",
    "training_batched_stream = training_stream.partition(batch_size).map(pd.concat).map(aggregate)\n",
    "\n",
    "example = pd.DataFrame({'x': [0]}, index=[0])\n",
    "training_sdf = streamz.dataframe.DataFrame(training_batched_stream, example=example)\n",
    "\n",
    "training_raw_buffer = Buffer(training_sdf, length=max_batches_to_show)\n",
    "training_smooth_buffer = Buffer(training_sdf.x.rolling(rolling_size).median())\n",
    "training_raw_dmap = hv.DynamicMap(hv.Curve, streams=[training_raw_buffer]).relabel('raw')\n",
    "training_smooth_dmap = hv.DynamicMap(hv.Curve, streams=[training_smooth_buffer]).relabel('smooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v2')\n",
    "agent = DecompAgent()\n",
    "episode_i = 0\n",
    "best_sample_avg = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=700 height=200 show_grid=True tools=['hover']]\n",
    "training_raw_dmap # * training_smooth_dmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 100000\n",
    "window = 100\n",
    "episode_returns = deque(maxlen=window)\n",
    "min_return = np.inf\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    episode, episode_return = train_episode(env, agent)\n",
    "    episode_returns.append(episode_return)\n",
    "    if episode_return < min_return:\n",
    "        min_return = episode_return\n",
    "        min_return_episode = episode\n",
    "\n",
    "    # best 100 sample average    \n",
    "    if len(episode_returns) >= window:\n",
    "        sample_average = np.mean(episode_returns)\n",
    "        best_sample_avg = max(best_sample_avg, np.mean(episode_returns))\n",
    "        # output\n",
    "        if i % 100 == 0:\n",
    "            training_stream.emit( pd.DataFrame({'x': sample_average}, index=[episode_i]) )\n",
    "        if i % 100 == 0:\n",
    "            sys.stdout.write('\\r' + \"Episode: \" + str(episode_i)+ \" best avg: \" + str(best_sample_avg))\n",
    "    #\n",
    "    episode_i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_q = np.max(agent.sub_agent.Q, axis=3)\n",
    "average_q_da = xr.DataArray(average_q, coords=[('row',range(5)), ('col',range(5)), ('dest',range(4))], name='average_q')\n",
    "\n",
    "policy = np.argmax(agent.sub_agent.Q, axis=3)\n",
    "policy_r = xr.DataArray(np.ones(policy.shape), coords=[('row',range(5)), ('col',range(5)), ('dest',range(4))], name='mag')\n",
    "policy_theta = xr.DataArray(policy, coords=[('row',range(5)), ('col',range(5)), ('dest',range(4))], name='angle')\n",
    "policy_theta = xr.where(policy_theta == 0, math.radians(90), policy_theta)\n",
    "policy_theta = xr.where(policy_theta == 1, math.radians(270), policy_theta)\n",
    "policy_theta = xr.where(policy_theta == 2, math.radians(0), policy_theta)\n",
    "policy_theta = xr.where(policy_theta == 3, math.radians(180), policy_theta)\n",
    "\n",
    "ds = hv.Dataset(xr.merge([policy_theta, policy_r, average_q_da]))\n",
    "policy_field = ds.to(gv.VectorField, ['col', 'row'], ['angle', 'mag'])\n",
    "average_q_img = ds.to(hv.Image, ['col', 'row'], ['average_q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts VectorField [width=200, height=200, invert_yaxis=True] (scale=1.5, line_width=3, color='black')\n",
    "policy_field.redim.range(row=(-0.5, 4.5), col=(-0.5, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [tuple( [x for x in agent.decode_state(s)[-3::-1]])+(a,r)  for s,a,r in min_return_episode]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=200, height=200, invert_yaxis=True] \n",
    "%%opts Points [invert_yaxis=True] (size=10, color='red')\n",
    "%%opts Curve  [invert_yaxis=True] (line_width=1, color='red')\n",
    "average_q_img * hv.Curve(path) * hv.Points(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
