{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews.streams import Pipe, Buffer\n",
    "\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "import streamz\n",
    "import streamz.dataframe\n",
    "\n",
    "import random, sys, gym, math, bokeh, pdb, time\n",
    "\n",
    "from simple_agent import SimpleAgent\n",
    "from drop_pick_agent import DropPickAgent\n",
    "from decomp_agent import DecompAgent\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_episode(env, agent):\n",
    "    state = env.reset()\n",
    "    episode_return = 0\n",
    "    episode = []\n",
    "    while True:\n",
    "        action = agent.select_action(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        \n",
    "        episode_return += reward\n",
    "        episode.append((state, action, reward))\n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            return episode, episode_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate episodes into batches\n",
    "batch_size = 1\n",
    "\n",
    "# Only show this many batches at once\n",
    "max_batches_to_show = 100000\n",
    "\n",
    "# Also apply rolling average to a certain window of batches\n",
    "rolling_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "    df.x = int(df.mean(0))\n",
    "    return df.head(1)\n",
    "\n",
    "training_stream = streamz.Stream()\n",
    "training_batched_stream = training_stream.partition(batch_size).map(pd.concat).map(aggregate)\n",
    "\n",
    "example = pd.DataFrame({'x': [0]}, index=[0])\n",
    "training_sdf = streamz.dataframe.DataFrame(training_batched_stream, example=example)\n",
    "\n",
    "training_raw_buffer = Buffer(training_sdf, length=max_batches_to_show)\n",
    "training_smooth_buffer = Buffer(training_sdf.x.rolling(rolling_size).median())\n",
    "training_raw_dmap = hv.DynamicMap(hv.Curve, streams=[training_raw_buffer]).relabel('raw')\n",
    "training_smooth_dmap = hv.DynamicMap(hv.Curve, streams=[training_smooth_buffer]).relabel('smooth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v2')\n",
    "agent = DecompAgent()\n",
    "episode_i = 0\n",
    "best_sample_avg = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=700 height=200 show_grid=True tools=['hover']]\n",
    "training_raw_dmap # * training_smooth_dmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 100000\n",
    "window = 100\n",
    "episode_returns = deque(maxlen=window)\n",
    "min_return = np.inf\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    episode, episode_return = train_episode(env, agent)\n",
    "    episode_returns.append(episode_return)\n",
    "    if episode_return < min_return:\n",
    "        min_return = episode_return\n",
    "        min_return_episode = episode\n",
    "\n",
    "    # best 100 sample average    \n",
    "    if len(episode_returns) >= window:\n",
    "        sample_average = np.mean(episode_returns)\n",
    "        best_sample_avg = max(best_sample_avg, np.mean(episode_returns))\n",
    "        # output\n",
    "        if i % 100 == 0:\n",
    "            training_stream.emit( pd.DataFrame({'x': sample_average}, index=[episode_i]) )\n",
    "        if i % 100 == 0:\n",
    "            sys.stdout.write('\\r' + \"Episode: \" + str(episode_i)+ \" best avg: \" + str(best_sample_avg))\n",
    "    #\n",
    "    episode_i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.sub_agent.epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[agent.decode_state(s)[0:2] for s,a,r in min_return_episode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_q = np.max(agent.sub_agent.Q, axis=3)\n",
    "average_q_da = xr.DataArray(average_q, coords=[('row',range(5)), ('col',range(5)), ('dest',range(4))], name='average_q')\n",
    "\n",
    "policy = np.argmax(agent.sub_agent.Q, axis=3)\n",
    "policy_r = xr.DataArray(np.ones(policy.shape), coords=[('row',range(5)), ('col',range(5)), ('dest',range(4))], name='mag')\n",
    "policy_theta = xr.DataArray(policy, coords=[('row',range(5)), ('col',range(5)), ('dest',range(4))], name='angle')\n",
    "policy_theta = xr.where(policy_theta == 0, math.radians(90), policy_theta)\n",
    "policy_theta = xr.where(policy_theta == 1, math.radians(270), policy_theta)\n",
    "policy_theta = xr.where(policy_theta == 2, math.radians(0), policy_theta)\n",
    "policy_theta = xr.where(policy_theta == 3, math.radians(180), policy_theta)\n",
    "\n",
    "ds = hv.Dataset(xr.merge([policy_theta, policy_r, average_q_da]))\n",
    "policy_field = ds.to(gv.VectorField, ['col', 'row'], ['angle', 'mag'])\n",
    "average_q_img = ds.to(hv.Image, ['col', 'row'], ['average_q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts VectorField [width=200, height=200, invert_yaxis=True] (scale=1.5, line_width=3, color='black')\n",
    "policy_field.redim.range(row=(-0.5, 4.5), col=(-0.5, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = [\n",
    "    \"+---------+\",\n",
    "    \"|R: | : :G|\",\n",
    "    \"| : : : : |\",\n",
    "    \"| : : : : |\",\n",
    "    \"| | : | : |\",\n",
    "    \"|Y| : |B: |\",\n",
    "    \"+---------+\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.argmax(agent.sub_agent.Q, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [tuple( [x for x in agent.decode_state(s)[-3::-1]])+(a,r)  for s,a,r in min_return_episode]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=200, height=200, invert_yaxis=True] \n",
    "%%opts Points [invert_yaxis=True] (size=10, color='red')\n",
    "%%opts Curve  [invert_yaxis=True] (line_width=1, color='red')\n",
    "average_q_img * hv.Curve(path) * hv.Points(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = np.arange(0, 2 * np.pi, .2), np.arange(0, 2 * np.pi, .2)\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "U = np.cos(X)\n",
    "V = np.sin(Y)\n",
    "\n",
    "# Convert U, V to magnitude and angle\n",
    "mag = np.sqrt(U**2 + V**2)\n",
    "angle = (np.pi/2.) - np.arctan2(U/mag, V/mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts VectorField [width=500 color_index=3 size_index=3 pivot='tip'] (cmap='fire' scale=0.8) Points (color='black' size=1)\n",
    "hv.VectorField((xs, ys, angle, mag)) * hv.Points((X.flat, Y.flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X == Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "\n",
    "def create_data():\n",
    "    \"\"\"\n",
    "    create fake example data\n",
    "    \"\"\"\n",
    "    times = [np.datetime64('2018-02-22 00:00:00')]\n",
    "    lons = np.arange(0, 360, 30)\n",
    "    # below fails\n",
    "    lats = np.arange(-90, 110, 20)\n",
    "    # below works\n",
    "    #lats = np.arange(-80, 100, 20)\n",
    "\n",
    "    dims = ('time', 'latitude', 'longitude')\n",
    "    shape = (len(times), len(lats), len(lons))\n",
    "    coords = {'latitude':lats, 'longitude':lons, 'time':times}\n",
    "\n",
    "    angle = np.zeros(shape)\n",
    "    mag = np.ones(shape)\n",
    "    angle_xr = xr.DataArray(angle, dims=dims, coords=coords)\n",
    "    mag_xr = xr.DataArray(mag, dims=dims, coords=coords)\n",
    "    xr_ds = xr.Dataset({'time': times, 'latitude': lats,\n",
    "        'longitude': lons,  'angle': (dims, angle), 'mag': (dims, mag)})\n",
    "        #'longitude': lons,  'angle': angle_xr, 'mag': mag_xr})\n",
    "    return xr_ds\n",
    "\n",
    "\n",
    "renderer = hv.renderer('bokeh')\n",
    "hv.output('size=200')\n",
    "hv.opts(\"Image [colorbar=True] (cmap='viridis') Curve [xrotation=60]\")\n",
    "\n",
    "xr_ds = create_data()\n",
    "vdims = ['angle', 'mag']\n",
    "kdims= ['time', 'latitude', 'longitude']\n",
    "gv_ds = gv.Dataset(xr_ds, kdims=kdims, vdims=vdims, crs=ccrs.PlateCarree())\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d %H'\n",
    "\n",
    "times = gv_ds.data.time\n",
    "hv.Dimension.type_formatters[np.datetime64] = '%Y-%m-%d %H'\n",
    "\n",
    "geo_dims = ['longitude', 'latitude']\n",
    "img = (gv_ds.to(gv.VectorField, geo_dims) * gf.coastline)\n",
    "\n",
    "gv_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
